<!DOCTYPE html>
<html lang="en">
<head>
<meta name="viewport" content="width=device-width, initial-scale=1">
</head>
<title>Cem Bozsahin: blog</title>
<html>
<head>
<title>Cem Bozsahin: blog</title>
<meta name="viewport" content="width=device-width,initial-scale=1">
</head>
<BODY>

<h2>Cem Bozsahin: a bloggy research statement</h2>

(a page for the light-hearted and forgiving; slightly more serious
things e.g. papers, tools and talks are in the research page.)


<p>
topics: ( <a href="#lang">linguistics</a> | <a href="#cogsci">cogsci</a> |
<a href="#computing">computer science</a> | <a href="#mind">mind thingy</a>
| <a href="https://www.youtube.com/playlist?list=PLfqjcz24ZBbGmXlWReGTNn02Ne0jaE9D3">videos</a>) 


<p> Some questions to ponder about forms and meanings: If some identical surface structures have different meanings, how do we learn these meanings?
If content is ambiguous (e.g. 'man' in 'the man' and 'man' in 'manned the aircraft with novices';
see <a href="http://hborer.sllf.qmul.ac.uk/">Borer</a> for a mind-blowing comic),
what fixes their unique structural interpretation?

<p> I am trying to see how far 'neither syntax nor semantics suffices by itself' idea can address
these questions. 

<p><a href="https://link.springer.com/epdf/10.1007/s11023-018-9469-2?author_access_token=4wGzHngyor3K7jK56OQg5ve4RwlQNchNByi7wbcMAY7DqkZi1yE-VRkTXN6U2PGC5R3CStqnaEN76U3AlKmpndwKPbV1cxHeRYIWtwqx8ACJBtACY9nycEg_nFPbLS4pAOM3dHpxOxcjct1DADU7_Q%3D%3D">Here</a> is one personal and more programmatic statement of the problem I can think of to build theories and models
to study these questions.

<p>(my apologies for upcoming verbosity; i wrote what follows to avoid confusing unsuspecting readers who have asked me about things here;
my short answers appear to be more confusing.)</p>

<p>(colleagues: please ignore philosophy-of-sciencey chit-chat that follows; this is, after all, the web.)

<hr>

In short: 

<p> I am a computer scientist. To me, it's all about human extended practice, not extended-human practice.
I'm trying to understand the scientific, subcultural, technological
and philosophical implications of that,  assuming the following
(and no, i am not a pancomputationalist or born-again computationalist, since you asked. I wrote <a href="https://www.academia.edu/9329448/What_is_a_computational_constraint">this</a>  and <a href="https://link.springer.com/epdf/10.1007/s11023-018-9469-2?author_access_token=4wGzHngyor3K7jK56OQg5ve4RwlQNchNByi7wbcMAY7DqkZi1yE-VRkTXN6U2PGC5R3CStqnaEN76U3AlKmpndwKPbV1cxHeRYIWtwqx8ACJBtACY9nycEg_nFPbLS4pAOM3dHpxOxcjct1DADU7_Q%3D%3D">that</a> about that.):

<ol>
<li> Cognitive science is study of natural minds with computers.
<li> Computer science is science of computers, and science with computers.
<li> Computer engineering is realizing the idea of the computer. (yes, there is just one)
<li> Computer science and linguistics have similar ways to explore,
	and seem to stand in contrast with psychology and philosophy. (yes, this one's for a bit of soul searching in cogsci).
</ol>

<p>Somewhat surprisingly, for some, all of these go back to one chap: Alan Turing. (Yes, he got us into trouble
from day one by making an unfortunate analogy between humans and computers, but that was a long time ago,
and trouble is his second name.)
The first idea is Turing's thesis (not Church-Turing thesis), which is essentially the beginning of
cogsci. The second idea is what Newell and Simon thought about the Turing Machine. The third idea started with Turing's
ACE, which is essentially an electronic universal TM (let's face it; other `first computers' were 
kludges). The fourth idea is now-forgotten collaboration of CS and linguistics, and it's time to get back to it, after a momentary Chomskyan lapse into other corners of science making.

<p>
Better minds can tell you the same story in a different way. 
Dennett might say item 1 leverages intentional stance to think there are also
artificial minds.
Knuth might say item 2 is attempting the question
`what can be automated?'. Von Neumann would say item 3 is attempting the question `how can we automate it?'. 
Item 1 is what I wish Turing had said but he said a bit more 
than that, and got us into trouble from day one. Speaking of trouble, check out item 4.

<p>As a computer scientist, I moonlight as a linguist and occasional philosopher, 
and foray into computational linguistics and cogsci, always ending 
up in my own den. 

<hr>
<p> Slightly longer:
<p align=justify>
I am a grammarian. (Some say a pig-headed one; I take that as a compliment.)
I look at morphology-phonology-lexicon-syntax-semantics relation(s)
as a cognitive scientist and try to understand their computational mechanisms. It's easier to call all that just 'grammar'. Grammars are not only for language; plans, audio systems and visual systems (and buildings!)
have grammars too. Theory of grammar looks at these problems as <b>indirect</b> association of forms and meanings, with
explicit arguments about resource boundedness of their computation.

<p> Grammar is a simple (but not simplistic) tool to explore, and perhaps
explain some of the things we explore. 
The garden variety comes with syntax only, but semantics don't grow on trees, so
it becomes more exploratory if we think of grammar as a correspondence. 
<p>
I study linguistic, computational, cognitive and philosophical aspects of grammars, more or less in this order of involvement.
I also look at how perception can give rise to knowledge in a haphazard
and bumpy sort of way. Nowadays this is called `dynamics'.
I prefer to think of it as clumsy computing of the discrete variety. (Clumsiness
comes from complexity in nature, not from bungling agents.)
Computationalism of the discrete kind makes a narrower claim in a wider
range of cognitive problems than
cognitivism, connectionism or dynamical systems. I also happen to believe that
it is more testable.

<p> Once we 
<a href="strict-lexicalization.pdf">strictly or radically lexicalise a grammar</a>, word learning
and language acquisition converge onto the same problem, whatever that is.
It is an indirect way of attempting to understand the nature of the 
problem. We are empirically well-grounded in this affair, because
human languages are provably non-context-free, and we can strictly lexicalise
the most restrictive super class of context-free grammars we have found so far, the linear-indexed grammars. The curious thing is that, once we do that, ie
strictly lexicalise a descriptively adequate grammar, we end up
with limited kinds of semantic dependencies, although syntax seems to be so, ehm, infinite. Understanding the limited nature of this problem forces 
'infinity' to play second fiddle in linguistics. 

<p> Kindly note that I am not promoting finitism, which is a school of mathematics
that uses some ideas of constructive mathematics (finite number of operations). 
I am suggesting that explaining why an infinite space has finite number of properties is more exciting. So i assume from the beginning that there can be potential infinity. (Potential/real infinity goes back to Aristotle, 
and comes back in linguistics to haunt us.)
Saying that that's because we have finite number of rules is not very exciting (not to me, at least), until we say something
more about these rules. 
Once we understand that, we might say, "oh by the way, it's potentially infinite.'' 

<p> Let me exemplify. Take four words of the set W = {I,you,think,like}. (Actually that's
nine word forms but lets not nitpick like a morphologist.) We can create an 
infinite language from W: I like you. I think I like you. You think I like you.
I think you think I like you. You think I think you think I like you, etc.etc. We can say that two rules are at work
here, one for transitives like `like' and one for complement-takers like
`think'. Right. Then why don't we get: I like I think I like you? 
Easy: 'like' is not a
complement-taker like `think'. So the difference between the two rules explains the odd case. 
Now, consider why `think' is capable of doing it while `like' is not: it takes a complement that can take its own arguments. If you cannot do that, you're stuck
with words like `like'. Now, that's *one* explanation for two rules.

<p> 
Now assume you want to take on board 
another
process that is commonly unbounded: relativisation. If you go the 'finite rules'
way of explaining infinity, there is one more rule to explain, that of relativisation. If you go the finite-dependencies way, you can use the unique explanation above. That's one explanation for three rules. This is not a 
meaning-determines-form explanation, it is about codeterminism of
semantics and constituency.  
And you can check the syntactic reflex of that in all languages.
(What we have done
is a mini practice of von Humboldtian (or generative) `infinity-in-finiteness' explanations,
which presume infinity, and Schonfinkelian (or combinatory) `explaining infinity'.)

<p>
Notice that in the W-experiment we get infinity too: any argument-taking argument can do this,
and no argument without arguments can. 

<p> One of my greatest teachers (Aryeh Faltz) once told me that anything finite is inherently boring. It is parochial. Why would anyone write a grammar to understand a finite number of dependencies? just list them all and be done with it. I believed in that dictum for a long time, but now i'm having second thoughts. It all depends on how we deal with finiteness. In this business, numbers can be everything, contra popular belief.

<p> A finite but very large language, say one with 10^200 sentences, needs a search algorithm to see which structures are realised, eventhough, after that search,
the meaning seems just retrieval, not composition. Search is
needed for an infinite language too, minus the semantic retrieval bit, 
which one must compose. If we know how to compose meanings, we can do
that for finite systems too, and use it as an argument to show that
their structures are made up of simple and finitely many primitives.
The more interesting question is, infinite languages appear to have
finite dependencies in them. So it seems that things can be finite <b>and</b>
interesting. After all, the universe appears to be finite,
but we wouldn't take all atoms in the universe as its explanation. Enter boundedness.
<hr>

<a name="lang">
<h3> The Language bit</h3>


<p>The interesting bit in linguistic theorising 
is that human languages exhibit limited semantic dependencies in their syntax.
We would like to know why. 
A strong hypothesis in this respect is that languages differ only
in their lexicons, and an invariant combinatorics gives semantics to order, and order alone, to lead to limited constituency and dependency. Common dependencies need not be stipulated in grammars, only the language specific ones.
From this perspective, infinity of languages (therefore recursion) is of secondary interest. I am beginning to think this is a stronger hypothesis than infinity (in the sense that it takes more burden of proof in its shoulders).
I am in favour of testing strong hypotheses 
before we entertain the weaker ones.
My high school best buddy told me to do that (well, more or less).
I usually don't do what I'm told but I make exceptions.

<p>
Lexicalising a grammar is crucial for this hypothesis.
The underlying idea in fully lexicalising a grammar is the notion
of "possible lexical category," as models of what 
<a href="http://en.wikipedia.org/wiki/Edmund_Husserl">
Edmund Husserl </a> called
"sensibly distinct representations in the mind."
Many of us (radical lexicalists) 
believe categories need explanation, rather than stipulation.
NB. these kinds of categories are knife edges: one side is syntactic, the other semantic. Any lexicalised grammar need do justice to both, unless we start
believing in one-edged knives. (The so-called one-edged knives, kard, culter, facon etc. are knives
with one edge <b>sharpened</b>, since you asked).

<p>
I try to work towards a theory of grammar.
When we radically lexicalise a grammar, something weird happens to words. 
By definition they are exceptional because they are all different, 
but they begin to bear combinatory categories that must be all over 
the grammar as a recycled resource. This resource and its recycling needs a theory. 
Naturally, something 'idiosyncratic' does not need a theory, so the theory we need 
must be about words' possible use in syntactic contexts, ie it must be about
constituency. 
Language is then a  closure of the lexicon with 
respect to an invariant (and finite) combinatory system.
(Having said that, I do believe language is a kludge; if I wanted
perfection in nature, I'd study sharks.) Lexicon is language with small el, l,
and its combinatorial theory is language with big el, L.
I guess what I'm saying is that a theory of kludge is a kludge too; it's 
turtles all the way down. 
<a href="http://en.wikipedia.org/wiki/Schonfinkel">Schonfinkel</a> 
called them combinators. They are nifty kludges to give semantics to order.

<p>
We can conceive the lexicon as something shaped by the invariant.
The invariant can be studied semiotically (extensionally) and 
psychologically (intensionally). The same goes for the lexicon.
But first we must account for Merrill Garrett's 
insight that ``parsing is a reflex.'' (try turning it off
if you're a skeptic). The part and parcel of the strong
hypothesis is that this is due to having a combinatory system that
is purely computational and oblivious to world matters. No movement, no ghost in the machine,
no checking, no caching, no tampering, no tinkering. What you do with that computation in real life is, ehem, the real meaning of life.
(What about the mind, you say. I don't know. 
These hefty global questions usually emanate from certain parts of
American East Coast. Ask them.) I am more interested in ecology-minded cogsci rather than mind-centered cogsci.

<p> More specifically,
i am interested in how combinatory and substantive constraints shape surface syntax,
and the lexical reflex of that effect. I am also
interested in
interactions in components--functionally speaking--of a language system: 
morphology, syntax, semantics, prosody, information structure, what have you.
Recently, I have been studying grammatical relations, word order, directionality and categorisation
in the lexicon, intonation in grammar, 
Bayesian sorcery for choosing categories, and morphosyntax, 
based on a theory of syntax-semantics called
<a href="http://groups.inf.ed.ac.uk/ccg">Combinatory Categorial Grammar</a> 
(CCG).

<table style="border:1px solid #aa0033; font-size:small" align=center>
  <tr>
      <td rowspan=3>
	       </td>
	           <td colspan=2 align=center><b>Subscribe to ankara-linguistic-circle</b></td>
		     </tr>
		       <form action="http://groups.google.com/group/ankara-linguistic-circle/boxsubscribe">
		         <tr> 
			     <td>Email: <input type=text name=email></td>
			         <td>
				       <table 
				              style="background-color:#ffcc33;padding:2px;border:2px outset #ffcc33;">
					            <tr>
						            <td>
							             <input type=submit name="sub" value="Subscribe">
								             </td>
									           </tr>
										         </table>
											     </td>
											       </tr>
											          </form>
												    <tr><td colspan=2 align=center>
												       <a href="http://groups.google.com/group/ankara-linguistic-circle">Browse Archives</a> at <a href="http://groups.google.com/">groups.google.com</a>
												         </td></tr>
													 </table>

													 <hr>
													 
										<a name="cogsci">
										<h3> The Cogsci bit</h3>

<p>
I believe grammar can be one of the most productive and creative tools in model construction for cognitive science once it's taken off the dusty shelves of 
high school,
and from linguist's ivory tower. It relates directly to computation as we know it. But first a bit of how we might have gotten to that point (all guesswork, of course).
<p>
The major difference between trees and animals is that animals move and trees don't. Everything that moves has a nervous system. (Not necessarily a central
system, but a nervous system.) It seems that the whole need for a central nervous system arose because things that move must coordinate their movement and actions. (If you are in doubt, try tying your shoelaces as you run).
Or it could just be a serendipitous accident to give us the mother of all neurons in a single thunderstrike (or astrocytes, if you like), in which case I will close shop and worship Taranis.



<p> The point of cognitive science is to make sense of how coordinated activity can take place with what little perceptive abilities a species have, and
how task-specific knowledge can give rise to something more than the token experience. That's what David Hume suggested---well not in these words, and i'm a bit old-fashioned in this matter to leave the good words to their owners.

<p> When things move, they must track other objects and coordinate their actions. (An inquiring mind might estimate the potential lifetime of a mouse that seems to totally ignore a curious or hungry cat.)
A simple hypothesis, aka. the computationalist hypothesis, is that all kinds of coordinate action are more of the same stuff. What distinguishes the species is their resource endowment and life training (i.e. exposure to data). 
So maybe, just maybe, the most uniquely human cognitive trait, language, is more of the same stuff, with more resources and less training, rather than a gift to mankind or some kind of miracle. (read: the only miracle I believe in is the national lottery.) A bit of evolutionary patience might give us wonders, if you pardon the pun.
</table>
<p>
Here's a consensus list for top hundred works in cogsci:
<a href="http://tierra.aslab.upm.es/public/index.php?option=com_content&task=view&id=141&Itemid=65">Top 100</a>

<p>Just to exploit the benefits of a non-representative democracy, aka. web,
I publicise my own top ten+ list, for whatever it's worth:<sup><a href="#fn1" id="ref1">a</a></sup>
<a href="cogsci-top10-cb.html">my cogsci top ten</a>
<a name="computing">

<hr>
<h3>The computation bit</h3>

<p> There seems to be a lot of confusion about what computation can do and must do in cognition. Myself being one of the confused, I try to convince students (and usually fail) that just because you use a computer to model does not mean you are a computationalist. Just because you don't use a computer does not mean
you are not a computationalist. (I tend to think Panini was computationalist,
and ACT-R is not. ACT-R is software engineering for cogsci, much like HPSG is for linguistics.)
Just because you think symbols are natural
representations for the mind does not mean that we've got a Turing machine running in our heads. Some psychologists might think that's computationalism, but it isn't. (Trust me, not all of them think like that.)

<p>
Computationalism is a style of thinking which suggests that 
computational principles (discreteness, complexity, resource boundedness) carve
the hypothesis space of higher-level cognitive processes.
Easier solutions appear earlier than more difficult ones. But, easy solutions may not be enough, because we face
multiple constraints in a complex life. In other words, the problem space could be general,
perhaps divided into classes of problems according to their demands,
but the solution is task-specific. Computational ease, difficulty and comprehensiveness are 
measured by complexity in time and space, automata-theoretic demands,
frequency (for biased search), completeness, decidability. We've got theories
about these things, which go under the names Complexity Theory, Algorithms,
Automata Theory and Logic.

<p>
Two examples: 1) Suppose we have a string of n words. Suppose also that
the problem is figuring out what parts of the string means what.
In Quine's sense, there are infinitely many possibilities. In Siskind's sense,
the possibilities are reduced to likelihoods by parsimony, e.g. exclusivity
of potential meanings, cross-situational inference etc. We must also
allow for the posibility that a sequence of words in the string could mean one thing, like in an idiom. Without constraints, there are O(2^n) possibilities to look at. (It is the powerset of n elements.)
With Zettlemoyer and Collins constraint, that only contiguous substrings
can have a pindownable meaning, the possibilities reduce to O(n^2). Any n larger than 4
can tell you why we must do something like this. Then we begin to worry
about what this contiguity assumption brings to cognition, and whether it is
attested elsewhere in the cognitive world. A cognitivist 
theory might start with assumptions like: nouns are learned first because
they stand for objects and there are lots of objects around. Computationalists
would say short, frequent, unambiguous, perhaps long but repetitive words are learned first because
we know that these properties make the problem computationally easier. You decide.
<p>
2) Think of word learning again.
This time as a language game as in Luc Steels's Talking Heads. 
(ok real ones are more talkative, and much better in music.) A group
of agents try to learn communication, which we measure by success of building
a common vocabulary in one-on-one interaction of speaker-hearer role play.
Some cognitivist assumptions could be "avoid homonymy, avoid synonymy". 
To a computationalist, that puts the cart before the horse. We can
see through simulations that homonymy and synonymy will cause unstable
systems or late convergence to common vocabulary at best. They are effects,
not causes. If people want to communicate (now that's a cause), and figure out that
agreeing on meanings of labels is a simple way to do that, we get limited
homonymy and synonymy and convergence. Do you know of a language
in which homonymy and synonymy are completely absent? Why don't we avoid
them completely if we're at it? Maybe that's not what we're doing, but
that's what we are getting. (We conducted this experiment, which we report 
<a href="https://www.academia.edu/8305262/Lexical_Redundancy_Naming_Game_and_Self-constrained_Synonymy">here</a>.)

<p> I guess what i seem to be saying is that functionalism
is a ghost that I am trying to exorcise.

<p> In sum, if I were  a rich man, I would take 
AMT as my main inspiration, Allen Newell as my friendly psychologist (yes,
i chose a computer guy as my psychic guide, so what?), Chomsky as the scientist, with care, minus the romanticism, much less the baroque nativism (as opposed
to more sensible variety), for what seems like an inner
drive for explanations, but also for public relations (he insists on
computation although in a weird way, but is good for business), 
Montague and Curry as design engineers 
(nb. rigorous models), Hume as the boss (now that's a big wig,
because it has to cover large territory), 
Husserl as the heavyweight philosopher (he's got a big beard to prove it too, unlike the islander variety, or the wrong side of the Atlantic variety--a great one: Fodor, and it's great in this business if half of what you say makes sense),
Wittgenstein as the master spoiler for that dormant cognitivist
lurking in all of us, and for fun (my cats talk to me; i would
like to return the favour),
Darwin as my gentle naysayer without academic quibbles (the man almost gave up his life's work
upon a single letter from New Zealand), Lamarck as my constant
reminder (he was wrong, as we will all be one day, perhaps even now, but
he was a bloody good scientist),
and Haj Ross as the linguist (name one syntactic nut to crack
that you cannot trace back to JRR or NC). I am guessing a person of these likenesses might
materialise in the 23rd century. 
<p>

<hr>
<p> To the (potential) students, friends, fiend  or 
foe who ask me whether i am an internalist,
externalist, realist, mentalist, instrumentalist, eliminativist, 
empiricist, rationalist, physicalist, 
materialist, idealist, functionalist and what not,  i can say this much (sorry for the presumption; i've been asked this question too many times--i don't
think my answers have been cohesive or consistent):
it seems that finding an interesting AND workable subset of these principles
and ideas to everyone's satisfaction is an admirable task (assuming that finding an interesting OR
workable subset is boring). But life's short. I wouldn't mind if the label 
comes later. I thought i was safe with the labels `realist', `naturalist' and  `computationalist' but life's full of surprises. So I try to follow the 
pillow-book approach for some scientific fun.
If a book of 10th century can tell us so much about
life just by listing people, birds, dogs, trees, rain, snow etc., I'd like some of that.

<!--
<p>
To phil of cogsci students in particular (please read this after the course,
if you can resist the temptation): eliminative materialism
might just be science envy for the philosopher; functionalism might just be engineering envy for
the scientist and the philosopher, and philosophy envy for the engineer; Chomskyanism is physics envy for
the linguist; instrumentalism is too much indulgence in agnosticism. 
(Actually i tend to think that the whole idea of analytic philosophy---
Russell and Quine excepted--might just be
empirical envy for the philosopher; we don't see hardcore
mathematicians falling into that trap---sorry Curry.)

<p>
Can we do some real work now?
-->
<a name="mind">
<hr><h3>Some surprising facts about the mind</h3>
<ol>
<li> <a href="https://www.youtube.com/watch?v=nBSUSXkYhwI">To door or not to door</a>
<li> <a href="https://www.youtube.com/watch?v=MFzDaBzBlL0">Bikes: can, can't</a>
<li> <a href="https://www.youtube.com/watch?v=JEXr9VpU1SI">Scaffolding
the bike recovery </a>
<li> <a href="http://www.bbc.com/news/uk-england-bristol-20801334">Born to be Welsh</a>
<li> <a href="https://jshd.pubs.asha.org/article.aspx?articleid=1783147">
From echolalia to grammar</a>
<li> <a href="https://www.youtube.com/watch?v=cbSu2PXOTOc&t=29s">The crow mind</a>
<li> <a href="https://www.ncbi.nlm.nih.gov/pubmed/18424224">The chimp mind</a>
<li> <a href="http://www.visualcapitalist.com/wp-content/uploads/2017/09/cognitive-bias-infographic.html">Mind: your own business</a>
</ol>


<hr>
<p> I blame Beckett for legitimising schoolboy humour in public places (and
<a href="http://specgram.com/">these guys</a>).
Actually I blame Sam for everything, because he's dead.

<p>
<sup id="fn1">a. OK I confess. I was asked by a student.<a href="#ref1" title="Jump back to footnote a in the text.">^</a></sup>
<hr>
Cognitive Science Department<br>
Informatics Institute<br>
Middle East Technical University<br>
06800 Ankara, Turkey 
</body>
</html>
